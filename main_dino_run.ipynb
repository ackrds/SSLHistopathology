{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ackrds/SSLHistopathology/blob/main/main_dino_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tifffile\n",
        "!pip install timm\n",
        "\n",
        "import os\n",
        "import tqdm\n",
        "import glob\n",
        "import tifffile\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import Subset\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd /content/gdrive/MyDrive/Transformers/dino\n",
        "\n",
        "import utils\n",
        "import vision_transformer as vits\n",
        "from vision_transformer import DINOHead\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BASE_DIR = '/content/gdrive/MyDrive/Transformers/dino'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfwAG7pxBIAQ",
        "outputId": "34f68fe3-452f-4e23-e039-87cbcff77f56"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (2023.7.18)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tifffile) (1.22.4)\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 timm-0.9.2\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Transformers/dino\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3r5rbKF5uyp",
        "outputId": "b08ca3ab-bd1e-4cfa-ce3b-cf928a7ec61f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/Transformers/dino/main_dino.py\", line 25, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1465, in <module>\n",
            "    from . import _meta_registrations\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 7, in <module>\n",
            "    from torch._decomp import _add_op_to_registry, global_decomposition_table, meta_table\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\", line 169, in <module>\n",
            "    import torch._decomp.decompositions\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py\", line 10, in <module>\n",
            "    import torch._prims as prims\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py\", line 33, in <module>\n",
            "    from torch._subclasses.fake_tensor import FakeTensor, FakeTensorMode\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/__init__.py\", line 3, in <module>\n",
            "    from torch._subclasses.fake_tensor import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 13, in <module>\n",
            "    from torch._guards import Source\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_guards.py\", line 14, in <module>\n",
            "    import sympy  # type: ignore[import]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\", line 73, in <module>\n",
            "    from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/__init__.py\", line 75, in <module>\n",
            "    from .polyfuncs import (symmetrize, horner, interpolate,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/polyfuncs.py\", line 11, in <module>\n",
            "    from sympy.polys.specialpolys import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/specialpolys.py\", line 297, in <module>\n",
            "    from sympy.polys.rings import ring\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/polys/rings.py\", line 30, in <module>\n",
            "    from sympy.printing.defaults import DefaultPrinting\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/__init__.py\", line 5, in <module>\n",
            "    from .latex import latex, print_latex, multiline_latex\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/printing/latex.py\", line 18, in <module>\n",
            "    from sympy.tensor.array import NDimArray\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/tensor/__init__.py\", line 4, in <module>\n",
            "    from .indexed import IndexedBase, Idx, Indexed\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/tensor/indexed.py\", line 114, in <module>\n",
            "    from sympy.functions.special.tensor_functions import KroneckerDelta\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sympy/functions/__init__.py\", line 26, in <module>\n",
            "    from sympy.functions.special.error_functions import (erf, erfc, erfi, erf2,\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1439, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1411, in _get_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1548, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1599, in _fill_cache\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python main_dino.py --arch vit_small --patch_size 16 --out_dim 65536  --momentum_teacher 0.996 --use_bn_in_head False --warmup_teacher_temp 0.04 --teacher_temp 0.04 --warmup_teacher_temp_epochs 0 --weight_decay 0.04 --weight_decay_end 0.4 --clip_grad 3.0 --batch_size_per_gpu 64 --epochs 100 --freeze_last_layer 1 --lr 0.0005 --warmup_epochs 10 --min_lr 1e-6 --optimizer adamw --drop_path_rate 0.1 --global_crops_scale 0.4 1.0 --local_crops_number 8 --local_crops_scale 0.05 0.4  --output_dir './logs/' --saveckp_freq 20 --seed 0 --num_workers 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eU9iHhjZm3oq"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/gdrive/MyDrive/ADPathology/Data/crc-100k/NCT-CRC-HE100K'\n",
        "val_dir = '/content/gdrive/MyDrive/ADPathology/Data/crc-100k/CRC-VAL-HE-7K'\n",
        "\n",
        "classes = os.listdir(train_dir)[0:]\n",
        "\n",
        "train_transforms = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomVerticalFlip(p=0.5),\n",
        "    T.RandomRotation(15),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "])\n",
        "\n",
        "val_transforms = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "\n",
        "  def __init__(self, data_dir, transforms, classes=classes):\n",
        "    self.data_dir = data_dir\n",
        "    self.data_files = glob.glob(data_dir + '/*/*.tif', recursive=True)\n",
        "    self.classes = classes\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    self.img_dir = self.data_files[index]\n",
        "    self.label = self.img_dir.split('/')[-1].split('-')[0]\n",
        "    self.label = self.classes.index(self.label)\n",
        "    self.img = tifffile.imread(self.img_dir)\n",
        "    if self.transforms != None:\n",
        "      self.img = self.transforms(self.img)\n",
        "\n",
        "\n",
        "    return self.img, self.label\n",
        "\n",
        "train_dataset = Dataset(data_dir=train_dir, transforms=train_transforms)\n",
        "train_dataset1 = Subset(train_dataset, [i for i in range(32000,48000)])\n",
        "\n",
        "val_dataset = Dataset(data_dir=val_dir, transforms=val_transforms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Eu5cRk6EkGMr"
      },
      "outputs": [],
      "source": [
        "arch = 'vit_small'\n",
        "patch_size = 16\n",
        "drop_path_rate = 0.1\n",
        "out_dim = 65536\n",
        "\n",
        "student = vits.__dict__[arch](\n",
        "    patch_size=patch_size,\n",
        "    drop_path_rate=drop_path_rate,\n",
        ")\n",
        "embed_dim = student.embed_dim\n",
        "\n",
        "student = utils.MultiCropWrapper(student,\n",
        "    DINOHead(\n",
        "    embed_dim,\n",
        "    out_dim = out_dim,\n",
        "    use_bn=False,\n",
        "    norm_last_layer=True,\n",
        "))\n",
        "\n",
        "ckpt_path = BASE_DIR + '/logs/checkpoint0000.pth'\n",
        "state_dict = torch.load(ckpt_path, map_location='cpu')['student']\n",
        "state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "state_dict = {k.replace(\"backbone.\", \"\"): v for k, v in state_dict.items()}\n",
        "_, _ = student.load_state_dict(state_dict, strict=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cbCNzlZVPXu-"
      },
      "outputs": [],
      "source": [
        "def extract_embeddings(data_loader):\n",
        "  embeddings, labels = [], []\n",
        "  student.to(device)\n",
        "  for batch_imgs, batch_labels in tqdm.tqdm(data_loader):\n",
        "      batch_embeddings = student(batch_imgs.to(device))\n",
        "      embeddings.append(batch_embeddings.detach().cpu())\n",
        "      labels.append(batch_labels)\n",
        "\n",
        "  embeddings = torch.cat(embeddings, dim=0)\n",
        "  labels = torch.cat(labels, dim=0)\n",
        "  return data.TensorDataset(embeddings, labels)\n",
        "\n",
        "train_loader1 = data.DataLoader(train_dataset1, batch_size=64, shuffle=True, drop_last=False)\n",
        "val_loader = data.DataLoader(val_dataset, batch_size=64, shuffle=False, drop_last=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwN-VFfFj9YL",
        "outputId": "48d9c92d-f892-41fb-e6a7-50bf314c8d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 8/250 [06:49<3:20:07, 49.62s/it]"
          ]
        }
      ],
      "source": [
        "train_embeddings1 = extract_embeddings(train_loader1)\n",
        "torch.save(train_embeddings1, BASE_DIR + '/train_embeddings3.pt')\n",
        "\n",
        "# val_embeddings = extract_embeddings(val_loader)\n",
        "# torch.save(val_embeddings, BASE_DIR + '/val_embeddings.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGZyt3EbmLVS"
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten the input tensor\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = data.DataLoader(train_embeddings, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "input_dim = out_dim\n",
        "hidden_dim = 300000\n",
        "output_dim = 10  # Number of classes in MNIST dataset\n",
        "\n",
        "\n",
        "model = Classifier(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 1000\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f'Train Epoch: {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "# Evaluation loop\n",
        "# model.eval()  # Set model to evaluation mode\n",
        "# correct = 0\n",
        "# total = 0\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for images, labels in test_loader:\n",
        "#         images = images.to(device)\n",
        "#         labels = labels.to(device)\n",
        "\n",
        "#         outputs = model(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "# accuracy = correct / total\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPpCLH/96MnihU8CFV6ZyT4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}